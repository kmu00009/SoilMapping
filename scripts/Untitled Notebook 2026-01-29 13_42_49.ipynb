{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2253a341-d3cc-4999-a97d-310e29bfffb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "pathP = Path(os.environ.get('PREDICT_DIR', '/dbfs/mnt/lab/unrestricted/KritiM'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2e6c753-0982-40db-a0e5-2f3105fa7e6f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import libraries"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from scipy import stats\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b651301a-bba3-4943-86a3-231e72b824b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Discover all Predict_* folders in pathP\n",
    "predict_folders = [f for f in pathP.iterdir() if f.is_dir() and f.name.lower().startswith('predict_')]\n",
    "print(f\"Discovered Predict folders: {[str(f) for f in predict_folders]}\")\n",
    "\n",
    "# Set output directory within pathP\n",
    "output_dir = pathP / 'outputMaps'a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "216333bc-9222-4ac8-8ff9-4b5f33836015",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find all unique grid names as the first five characters of each *_predict*.tif file\n",
    "grid_names = set()\n",
    "for folder in predict_folders:\n",
    "    for tif in folder.glob('*_predict*.tif'):\n",
    "        grid_names.add(tif.name[:5])\n",
    "\n",
    "grid_names = sorted(grid_names)\n",
    "\n",
    "print(f\"Found {len(grid_names)} grids to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc64911f-2fce-4c6a-85b7-93beb639818f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "def process_grid(grid, predict_folders, output_dir):\n",
    "    print(f\"\\nProcessing grid: {grid}\")\n",
    "    predict_paths = []\n",
    "    conf_paths = []\n",
    "    for folder in predict_folders:\n",
    "        pred = folder / f\"{grid}_predict_xgb.tif\"\n",
    "        conf = folder / f\"{grid}_confidence_xgb.tif\"\n",
    "        if pred.exists() and conf.exists():\n",
    "            predict_paths.append(pred)\n",
    "            conf_paths.append(conf)\n",
    "    if len(predict_paths) != 5 or len(conf_paths) != 5:\n",
    "        print(f\"  Skipping {grid}: found {len(predict_paths)} predictions and {len(conf_paths)} confidences.\")\n",
    "        return\n",
    "    print(f\"  Loading rasters for grid {grid}...\")\n",
    "    # Load and stack predictions and confidences\n",
    "    preds = []\n",
    "    confs = []\n",
    "    for p, c in zip(predict_paths, conf_paths):\n",
    "        with rasterio.open(p) as src:\n",
    "            preds.append(src.read(1))\n",
    "            meta = src.meta.copy()\n",
    "        with rasterio.open(c) as src:\n",
    "            confs.append(src.read(1))\n",
    "    preds = np.stack(preds, axis=0)  # shape: (5, H, W)\n",
    "    confs = np.stack(confs, axis=0)  # shape: (5, H, W)\n",
    "\n",
    "    # Mask invalid pixels (assume nodata is set in meta)\n",
    "    nodata = meta.get('nodata', None)\n",
    "    if nodata is not None:\n",
    "        mask = np.all(preds == nodata, axis=0)\n",
    "    else:\n",
    "        mask = np.zeros(preds.shape[1:], dtype=bool)\n",
    "\n",
    "    # Prepare output arrays\n",
    "    out_pred = np.full(preds.shape[1:], nodata if nodata is not None else 0, dtype=preds.dtype)\n",
    "    out_conf = np.full(confs.shape[1:], 0, dtype=confs.dtype)\n",
    "\n",
    "    print(f\"  Running ensemble logic for grid {grid}...\")\n",
    "    H, W = preds.shape[1:]\n",
    "    for i in tqdm(range(H), desc=f\"Grid {grid}\"):\n",
    "        for j in range(W):\n",
    "            if mask[i, j]:\n",
    "                continue  # all nodata, leave as is\n",
    "            pred_vals = preds[:, i, j]\n",
    "            conf_vals = confs[:, i, j]\n",
    "            valid = pred_vals != (nodata if nodata is not None else 0)\n",
    "            if not np.any(valid):\n",
    "                continue  # all invalid, leave as is\n",
    "            pred_vals = pred_vals[valid]\n",
    "            conf_vals = conf_vals[valid]\n",
    "            # Find mode(s)\n",
    "            mode_result = stats.mode(pred_vals, keepdims=True)\n",
    "            mode_val = mode_result.mode[0]\n",
    "            mode_count = mode_result.count[0]\n",
    "            # Check for ties\n",
    "            unique, counts = np.unique(pred_vals, return_counts=True)\n",
    "            max_count = np.max(counts)\n",
    "            tied_classes = unique[counts == max_count]\n",
    "            if len(tied_classes) == 1:\n",
    "                # Single mode\n",
    "                class_mask = pred_vals == tied_classes[0]\n",
    "                conf_subset = conf_vals[class_mask]\n",
    "                if conf_subset.size > 0:\n",
    "                    best_idx = np.argmax(conf_subset)\n",
    "                    best_class = tied_classes[0]\n",
    "                    best_conf = conf_subset[best_idx]\n",
    "                else:\n",
    "                    # Fallback: all confs are nan or empty\n",
    "                    best_class = tied_classes[0]\n",
    "                    best_conf = np.nan\n",
    "            else:\n",
    "                # Tie for mode\n",
    "                # Among tied, pick the one with highest confidence\n",
    "                best_conf = -np.inf\n",
    "                best_class = tied_classes[0]\n",
    "                found = False\n",
    "                for cls in tied_classes:\n",
    "                    class_mask = pred_vals == cls\n",
    "                    conf_subset = conf_vals[class_mask]\n",
    "                    if conf_subset.size > 0:\n",
    "                        max_conf = np.max(conf_subset)\n",
    "                        if max_conf > best_conf:\n",
    "                            best_conf = max_conf\n",
    "                            best_class = cls\n",
    "                        found = True\n",
    "                if not found:\n",
    "                    # Fallback: all confs are nan or empty\n",
    "                    best_class = tied_classes[0]\n",
    "                    best_conf = np.nan\n",
    "                else:\n",
    "                    # If still tied in confidence, pick first occurrence\n",
    "                    tied_conf = [np.max(conf_vals[pred_vals == cls]) if np.any(pred_vals == cls) else -np.inf for cls in tied_classes]\n",
    "                    if tied_conf.count(best_conf) > 1:\n",
    "                        for idx, cls in enumerate(pred_vals):\n",
    "                            if cls in tied_classes and conf_vals[idx] == best_conf:\n",
    "                                best_class = cls\n",
    "                                break\n",
    "            out_pred[i, j] = best_class\n",
    "            out_conf[i, j] = best_conf\n",
    "\n",
    "    print(f\"  Saving results for grid {grid} in {output_dir} ...\")\n",
    "    out_pred_path = output_dir / f\"{grid}_ensemble_predict.tif\"\n",
    "    out_conf_path = output_dir / f\"{grid}_ensemble_confidence.tif\"\n",
    "\n",
    "    # Write to temporary directory first, then move to output_dir\n",
    "    tmp_dir = tempfile.mkdtemp()\n",
    "    try:\n",
    "        tmp_pred = os.path.join(tmp_dir, f'{grid}_ensemble_predict.tif')\n",
    "        tmp_conf = os.path.join(tmp_dir, f'{grid}_ensemble_confidence.tif')\n",
    "        meta.update(dtype=out_pred.dtype, count=1)\n",
    "        \n",
    "        with rasterio.open(tmp_pred, 'w', **meta) as dst:\n",
    "            dst.write(out_pred, 1)\n",
    "        meta.update(dtype=out_conf.dtype, count=1)\n",
    "        \n",
    "        with rasterio.open(tmp_conf, 'w', **meta) as dst:\n",
    "            dst.write(out_conf, 1)\n",
    "        \n",
    "        shutil.copy2(tmp_pred, out_pred_path)\n",
    "        shutil.copy2(tmp_conf, out_conf_path)\n",
    "    finally:\n",
    "        shutil.rmtree(tmp_dir)\n",
    "        \n",
    "\n",
    "    print(f\"  Finished processing grid: {grid}. Output saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08300a31-755f-4db9-a44e-3aab67448ac5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Process all grids\n",
    "total_grids = len(grid_names)\n",
    "print(f\"\\nStarting processing of {total_grids} grids...\")\n",
    "for grid in grid_names:\n",
    "    process_grid(grid, predict_folders, output_dir)\n",
    "    \n",
    "        \n",
    "print(\"\\nAll grids processed.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2026-01-29 13_42_49",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
